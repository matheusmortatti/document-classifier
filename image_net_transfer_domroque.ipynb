{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Couldn't import dot_parser, loading of dot files will not be possible.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import keras\n",
    "import random\n",
    "import numpy as np\n",
    "import sys\n",
    "import operator\n",
    "import math\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, MaxPooling2D, Flatten, GlobalAveragePooling2D, Dropout\n",
    "from keras.applications import MobileNet\n",
    "from keras.applications.mobilenet import preprocess_input\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "from keras.models import model_from_json\n",
    "from keras.applications import InceptionResNetV2\n",
    "from keras.applications import VGG16\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img, save_img\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "from skimage import transform\n",
    "from skimage.io import imread, imsave, imshow\n",
    "from skimage.color import rgb2gray\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "import time\n",
    "\n",
    "current_milli_time = lambda: int(round(time.time() * 1000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    Preprocess image, normalizing and resizing it\n",
    "\n",
    "    :param frame: RGBA frame\n",
    "\"\"\"    \n",
    "def preprocess_image(frame):\n",
    "    \n",
    "    # Normalize Pixel Values\n",
    "    normalized_frame = frame/255.0 - 0.5\n",
    "    \n",
    "    # Resize\n",
    "    preprocessed_frame = transform.resize(normalized_frame, IMAGE_PP_SIZE)\n",
    "    \n",
    "    # Create a 3-Channel image\n",
    "#     final_image = np.dstack((preprocessed_frame, preprocessed_frame, preprocessed_frame))\n",
    "    \n",
    "    return preprocessed_frame\n",
    "\n",
    "\"\"\"\n",
    "    Create 2D label list from 1D list\n",
    "    \n",
    "    :param labels: 1D label list\n",
    "\"\"\"\n",
    "\n",
    "def make_labels(labels):\n",
    "    np_labels = np.zeros((len(labels), CLASS_NUMBER))\n",
    "    \n",
    "    for i in range(len(labels)):\n",
    "        np_labels[i, labels[i]] = 1\n",
    "    \n",
    "    return np_labels\n",
    "\n",
    "def file_len(fname):\n",
    "    with open(fname) as f:\n",
    "        for i, l in enumerate(f):\n",
    "            pass\n",
    "    return i + 1\n",
    "\n",
    "def choices(l, k=1):\n",
    "    new_list = []\n",
    "    for i in range(k):\n",
    "        new_list.append(random.choice(l))\n",
    "    return new_list\n",
    "\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "#     print(cm)\n",
    "    \n",
    "    plt.figure(num=None, figsize=(8, 6), dpi=80, facecolor='w', edgecolor='k')\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.tight_layout()\n",
    "    \n",
    "def VGG16_Model():\n",
    "    conv_base = VGG16(weights='imagenet', include_top=False, input_shape=(150,150,3))\n",
    "    conv_base.traiable = False\n",
    "    x = conv_base.output\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(4096, activation=\"relu\")(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = Dense(4096, activation=\"relu\")(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    predictions = Dense(7, activation=\"softmax\")(x)\n",
    "    \n",
    "    model = Model(input = conv_base.input, output = predictions)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Globals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_PP_SIZE = [150, 150]\n",
    "EPOCHS = 100\n",
    "BATCH_SIZE = 100\n",
    "TRAIN_STEP = 1591\n",
    "VAL_SIZE = 100\n",
    "CLASS_NUMBER = 7\n",
    "\n",
    "RELOAD_MODEL = False\n",
    "\n",
    "DATA_FOLDER_ROOT = \"/media/matheusmortatti/External/dom-roque\"\n",
    "DATA_FOLDER = \"/media/matheusmortatti/External/dom-roque/original\"\n",
    "DATA_FOLDER_PROCESSED = \"/media/matheusmortatti/External/dom-roque/preprocessed\"\n",
    "\n",
    "\n",
    "# Train, Val, Test\n",
    "DATA_RATIO = [0.6, 0.2, 0.2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DATA PREPROCESSING\n",
    "\n",
    "This cell will take all the images and preprocess it, saving the results onto another folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/matheusmortatti/.local/lib/python3.5/site-packages/skimage/transform/_warps.py:105: UserWarning: The default mode, 'constant', will be changed to 'reflect' in skimage 0.15.\n",
      "  warn(\"The default mode, 'constant', will be changed to 'reflect' in \"\n",
      "/home/matheusmortatti/.local/lib/python3.5/site-packages/skimage/transform/_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "/home/matheusmortatti/.local/lib/python3.5/site-packages/skimage/util/dtype.py:141: UserWarning: Possible precision loss when converting from float64 to uint8\n",
      "  .format(dtypeobj_in, dtypeobj_out))\n",
      "/home/matheusmortatti/.local/lib/python3.5/site-packages/skimage/io/_io.py:140: UserWarning: /media/matheusmortatti/External/dom-roque/preprocessed/balancete/DALLEMOLE.jpg is a low contrast image\n",
      "  warn('%s is a low contrast image' % fname)\n",
      "/home/matheusmortatti/.local/lib/python3.5/site-packages/skimage/io/_io.py:140: UserWarning: /media/matheusmortatti/External/dom-roque/preprocessed/balancete/DALLEMOLE_4.jpg is a low contrast image\n",
      "  warn('%s is a low contrast image' % fname)\n",
      "/home/matheusmortatti/.local/lib/python3.5/site-packages/PIL/Image.py:2575: DecompressionBombWarning: Image size (94080000 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.\n",
      "  DecompressionBombWarning)\n",
      "/home/matheusmortatti/.local/lib/python3.5/site-packages/skimage/io/_io.py:140: UserWarning: /media/matheusmortatti/External/dom-roque/preprocessed/LA/Energisa01_3.jpg is a low contrast image\n",
      "  warn('%s is a low contrast image' % fname)\n",
      "/home/matheusmortatti/.local/lib/python3.5/site-packages/skimage/io/_io.py:140: UserWarning: /media/matheusmortatti/External/dom-roque/preprocessed/LA/Energisa03_3.jpg is a low contrast image\n",
      "  warn('%s is a low contrast image' % fname)\n",
      "/home/matheusmortatti/.local/lib/python3.5/site-packages/skimage/io/_io.py:140: UserWarning: /media/matheusmortatti/External/dom-roque/preprocessed/LA/Energisa04_3.jpg is a low contrast image\n",
      "  warn('%s is a low contrast image' % fname)\n",
      "/home/matheusmortatti/.local/lib/python3.5/site-packages/skimage/io/_io.py:140: UserWarning: /media/matheusmortatti/External/dom-roque/preprocessed/LA/Energisa12_3.jpg is a low contrast image\n",
      "  warn('%s is a low contrast image' % fname)\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# If the folder doesn't exists yet, create it and preprocess all images\n",
    "#\n",
    "\n",
    "if not os.path.isdir(DATA_FOLDER_ROOT + '/preprocessed'):\n",
    "    os.mkdir(DATA_FOLDER_ROOT + '/preprocessed')\n",
    "    \n",
    "    labels = os.listdir(DATA_FOLDER)\n",
    "    for label in labels:\n",
    "        folder_path = DATA_FOLDER + '/' + label\n",
    "        if not os.path.isdir(folder_path):\n",
    "            continue\n",
    "        os.mkdir(DATA_FOLDER_PROCESSED + '/' + label)\n",
    "\n",
    "    for label in labels:\n",
    "        folder_path = DATA_FOLDER + '/' + label\n",
    "        if not os.path.isdir(folder_path):\n",
    "            continue\n",
    "\n",
    "        for root, dirs, files in os.walk(folder_path):\n",
    "            for file in files:\n",
    "                if file.split('.')[-1] != \"jpg\":\n",
    "                    continue\n",
    "                img_path = os.path.join(root, file)\n",
    "                img = imread(img_path)\n",
    "                x = preprocess_image(img)\n",
    "#                 x = array_to_img(x)\n",
    "#                 save_img(DATA_FOLDER_PROCESSED + '/' + label + '/' + file, x)\n",
    "                imsave(DATA_FOLDER_PROCESSED + '/' + label + '/' + file, x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DATA AUGMENTATION\n",
    "\n",
    "Running this cell will take your data folder and augment all the files within it.\n",
    "\n",
    "DO NOT RUN THIS CELL TWICE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1654\n",
      "\n",
      "7\n",
      "236\n",
      "\n",
      "/media/matheusmortatti/External/dom-roque/original/nf\n",
      "/media/matheusmortatti/External/dom-roque/original/nf/NF-E\n",
      "/media/matheusmortatti/External/dom-roque/original/nf/NFS\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# Create more data\n",
    "#\n",
    "\n",
    "folder = DATA_FOLDER\n",
    "\n",
    "datagen = ImageDataGenerator(rotation_range=5,\n",
    "                             width_shift_range=0.05,\n",
    "                             height_shift_range=0.05,\n",
    "                             shear_range=0,\n",
    "                             zoom_range=0.01)\n",
    "\n",
    "labels = os.listdir(folder)\n",
    "label_count = {}\n",
    "\n",
    "for label in labels:\n",
    "    folder_path = folder + '/' + label\n",
    "    if not os.path.isdir(folder_path):\n",
    "        continue\n",
    "\n",
    "    for root, dirs, files in os.walk(folder_path):\n",
    "        if label not in label_count:\n",
    "            label_count[label] = 0\n",
    "        label_count[label] += len(files)\n",
    "\n",
    "label_max = max(zip(label_count.values(), label_count.keys()))[0]\n",
    "print(label_max)\n",
    "print()\n",
    "\n",
    "for label in labels:\n",
    "    folder_path = folder + '/' + label\n",
    "    if not os.path.isdir(folder_path):\n",
    "        continue\n",
    "    \n",
    "    \n",
    "    if not os.path.isdir(folder_path + '/augmented'):\n",
    "        os.mkdir(folder_path + '/augmented')\n",
    "    else:\n",
    "        continue\n",
    "        \n",
    "    amount = math.ceil(label_max / label_count[label]) - 1\n",
    "    print(label_count[label])\n",
    "    print(amount)\n",
    "    print()\n",
    "\n",
    "    for root, dirs, files in os.walk(folder_path):\n",
    "        \n",
    "        if 'augmented' in root:\n",
    "            continue\n",
    "            \n",
    "        print(root)\n",
    "        \n",
    "        for file in files:\n",
    "            if file.split('.')[-1] != \"jpg\":\n",
    "                continue\n",
    "            img_path = os.path.join(root, file)\n",
    "            img = load_img(img_path)\n",
    "            x = img_to_array(img)  # this is a Numpy array with shape (3, 150, 150)\n",
    "            x = x.reshape((1,) + x.shape)  # this is a Numpy array with shape (1, 3, 150, 150)\n",
    "\n",
    "            i = 0\n",
    "            for batch in datagen.flow(x, \n",
    "                                      batch_size=1,\n",
    "                                      save_to_dir=folder_path + '/augmented', \n",
    "                                      save_prefix='_' + str(current_milli_time()), \n",
    "                                      save_format='jpg'):\n",
    "                i += 1\n",
    "                if i >= amount:\n",
    "                    break  # otherwise the generator would loop indefinitely"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Labels File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = DATA_FOLDER\n",
    "\n",
    "random.seed(current_milli_time())\n",
    "\n",
    "def choices(l, k):\n",
    "    c = []\n",
    "    for i in range(k):\n",
    "        el = random.choice(l)\n",
    "        c.append(el)\n",
    "        l.remove(el)\n",
    "    return c, l\n",
    "\n",
    "labels = os.listdir(folder)\n",
    "\n",
    "i = 0\n",
    "train = []\n",
    "test = []\n",
    "val = []\n",
    "for label in labels:\n",
    "    if not os.path.isdir(folder + '/' + label):\n",
    "        continue\n",
    "\n",
    "    for root, dirs, files in os.walk(folder + '/' + label):\n",
    "        f = []\n",
    "        for file in files:\n",
    "            if ('jpg' not in file) and ('jpeg' not in file):\n",
    "                continue\n",
    "            f.append(file)\n",
    "            \n",
    "        n = len(f)\n",
    "        n_train = int(DATA_RATIO[0] * n)\n",
    "        n_val = int(DATA_RATIO[1] * n)\n",
    "        n_test = int(DATA_RATIO[2] * n)\n",
    "\n",
    "        lt, f = choices(f, n_train)\n",
    "        for l in lt:\n",
    "            train.append(os.path.join(root, l) + \" \" + str(i) + \" \" + label + \"\\n\")\n",
    "\n",
    "        lt, f = choices(f, n_val)\n",
    "        for l in lt:\n",
    "            l = l.replace(' ', '\\ ')\n",
    "            val.append(os.path.join(root, l) + \" \" + str(i) + \" \" + label + \"\\n\")\n",
    "\n",
    "        lt, f = choices(f, n_test)\n",
    "        for l in lt:\n",
    "            l = l.replace(' ', '\\ ')\n",
    "            test.append(os.path.join(root, l) + \" \" + str(i) + \" \" + label + \"\\n\")\n",
    "\n",
    "        \n",
    "\n",
    "    i += 1\n",
    "\n",
    "random.shuffle(train)\n",
    "random.shuffle(val)\n",
    "random.shuffle(test)\n",
    "\n",
    "with open(folder + '/' + 'labels_train.txt', 'a') as f:\n",
    "    for l in train:\n",
    "        f.write(l)\n",
    "\n",
    "with open(folder + '/' + 'labels_val.txt', 'a') as f:\n",
    "    for l in val:\n",
    "        f.write(l)\n",
    "\n",
    "with open(folder + '/' + 'labels_test.txt', 'a') as f:\n",
    "    for l in test:\n",
    "        f.write(l)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Model or Create it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 150, 150, 3)       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 150, 150, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 150, 150, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 75, 75, 64)        0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 75, 75, 128)       73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 75, 75, 128)       147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 37, 37, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 37, 37, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 37, 37, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 37, 37, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 18, 18, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 18, 18, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 18, 18, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 18, 18, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 9, 9, 512)         0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 9, 9, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 9, 9, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 9, 9, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 4, 4, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 8192)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 4096)              33558528  \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 7)                 28679     \n",
      "=================================================================\n",
      "Total params: 65,083,207\n",
      "Trainable params: 65,083,207\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/matheusmortatti/.local/lib/python3.5/site-packages/ipykernel_launcher.py:88: UserWarning: Update your `Model` call to the Keras 2 API: `Model(outputs=Tensor(\"de..., inputs=Tensor(\"in...)`\n"
     ]
    }
   ],
   "source": [
    "if RELOAD_MODEL:\n",
    "    try:\n",
    "        json_file = open('/media/matheusmortatti/External/document-classifier/models/model_imgnet_domroque.json', 'r')\n",
    "        loaded_model_json = json_file.read()\n",
    "        json_file.close()\n",
    "        model = model_from_json(loaded_model_json)\n",
    "        # load weights into new model\n",
    "        model.load_weights('/media/matheusmortatti/External/document-classifier/weights/model_imgnet_domroque.h5')\n",
    "        print(\"here\")\n",
    "    except:\n",
    "        model = VGG16_Model()\n",
    "else:\n",
    "    model = None\n",
    "    model = VGG16_Model()\n",
    "    \n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.SGD(lr=0.01),\n",
    "              metrics=['accuracy'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/matheusmortatti/.local/lib/python3.5/site-packages/skimage/transform/_warps.py:105: UserWarning: The default mode, 'constant', will be changed to 'reflect' in skimage 0.15.\n",
      "  warn(\"The default mode, 'constant', will be changed to 'reflect' in \"\n",
      "/home/matheusmortatti/.local/lib/python3.5/site-packages/skimage/transform/_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "200\n",
      "300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/matheusmortatti/.local/lib/python3.5/site-packages/PIL/Image.py:2575: DecompressionBombWarning: Image size (94080000 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.\n",
      "  DecompressionBombWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "1400\n",
      "1500\n",
      "1600\n",
      "1700\n",
      "1800\n",
      "1900\n",
      "2000\n",
      "2100\n",
      "2200\n",
      "2300\n",
      "2400\n",
      "2500\n",
      "2600\n",
      "2700\n",
      "2800\n",
      "2900\n",
      "3000\n",
      "3100\n",
      "3200\n",
      "3300\n",
      "3400\n",
      "3500\n",
      "3600\n",
      "3700\n",
      "3800\n",
      "3900\n",
      "4000\n",
      "4100\n",
      "4200\n",
      "4300\n",
      "4400\n",
      "4500\n",
      "4600\n",
      "4700\n",
      "4800\n",
      "4900\n",
      "5000\n",
      "5100\n",
      "5200\n",
      "5300\n",
      "5400\n",
      "5500\n",
      "5600\n",
      "5700\n",
      "5800\n",
      "5900\n",
      "6000\n",
      "6100\n",
      "6200\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#\n",
    "# Define train, validation and test lists\n",
    "#\n",
    "\n",
    "folder = DATA_FOLDER\n",
    "\n",
    "train_labels = []\n",
    "val_labels = []\n",
    "test_labels = []\n",
    "\n",
    "train_input = []\n",
    "val_input = []\n",
    "test_input = []\n",
    "\n",
    "#\n",
    "# Load validation dataset\n",
    "#\n",
    "\n",
    "# labels_file = open(folder + \"/labels_val.txt\")\n",
    "\n",
    "\n",
    "# for line in labels_file:\n",
    "#     sp = line.split()\n",
    "    \n",
    "#     img = imread(sp[0])\n",
    "#     img = preprocess_image(img)\n",
    "    \n",
    "#     val_input.append(img)\n",
    "#     val_labels.append(int(sp[1]))\n",
    "\n",
    "# x_val = np.asarray(val_input)\n",
    "# y_val = make_labels(val_labels)\n",
    "    \n",
    "# labels_file.close()\n",
    "\n",
    "#\n",
    "# Load training dataset\n",
    "#\n",
    "    \n",
    "labels_file = open(folder + \"/labels_train.txt\")\n",
    "    \n",
    "for line in labels_file:\n",
    "    sp = line.split()\n",
    "    \n",
    "    img = imread(sp[0])\n",
    "    img = preprocess_image(img)\n",
    "    \n",
    "    train_input.append(img)\n",
    "    train_labels.append(int(sp[1]))\n",
    "    \n",
    "    if len(train_input)%100 == 0:\n",
    "        print(len(train_input))\n",
    "\n",
    "x_train = np.asarray(train_input)\n",
    "y_train = make_labels(train_labels)\n",
    "    \n",
    "labels_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA Analisys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7325, 150, 150, 3)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'Cumulative explained variance')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(x_train.shape)\n",
    "X_train = StandardScaler().fit_transform(x_train[:2000].reshape(2000, 150*150*3))\n",
    "pca = PCA(0.95)\n",
    "pca.fit(X_train)\n",
    "\n",
    "plt.plot(np.cumsum(pca.explained_variance_ratio_))\n",
    "plt.xlabel('Number of components')\n",
    "plt.ylabel('Cumulative explained variance')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "xp_train = pca.transform(x_train[:2000].reshape(2000, 150*150*3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator(x_train, y_train, batch_size = 100):\n",
    "    index = 0\n",
    "    while True:\n",
    "        yield (x_train[index:index+batch_size,], y_train[index:index+batch_size,])\n",
    "        index += batch_size\n",
    "        if index > x_train.shape[0]:\n",
    "            index = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "62/62 [==============================] - 107s 2s/step - loss: 0.2418 - acc: 0.9139\n",
      "Epoch 2/100\n",
      "62/62 [==============================] - 108s 2s/step - loss: 0.1567 - acc: 0.9446\n",
      "Epoch 3/100\n",
      "62/62 [==============================] - 110s 2s/step - loss: 0.1264 - acc: 0.9575\n",
      "Epoch 4/100\n",
      "62/62 [==============================] - 109s 2s/step - loss: 0.1139 - acc: 0.9607\n",
      "Epoch 5/100\n",
      "62/62 [==============================] - 109s 2s/step - loss: 0.0894 - acc: 0.9698\n",
      "Epoch 6/100\n",
      "62/62 [==============================] - 111s 2s/step - loss: 0.0759 - acc: 0.9743\n",
      "Epoch 7/100\n",
      "62/62 [==============================] - 108s 2s/step - loss: 0.0674 - acc: 0.9773\n",
      "Epoch 8/100\n",
      "62/62 [==============================] - 108s 2s/step - loss: 0.0516 - acc: 0.9817\n",
      "Epoch 9/100\n",
      "62/62 [==============================] - 107s 2s/step - loss: 0.0377 - acc: 0.9876\n",
      "Epoch 10/100\n",
      "62/62 [==============================] - 108s 2s/step - loss: 0.0436 - acc: 0.9866\n",
      "Epoch 11/100\n",
      "62/62 [==============================] - 108s 2s/step - loss: 0.0445 - acc: 0.9853\n",
      "Epoch 12/100\n",
      "62/62 [==============================] - 107s 2s/step - loss: 0.0298 - acc: 0.9892\n",
      "Epoch 13/100\n",
      "62/62 [==============================] - 107s 2s/step - loss: 0.0313 - acc: 0.9895\n",
      "Epoch 14/100\n",
      "62/62 [==============================] - 107s 2s/step - loss: 0.0274 - acc: 0.9903\n",
      "Epoch 15/100\n",
      "62/62 [==============================] - 108s 2s/step - loss: 0.0680 - acc: 0.9776\n",
      "Epoch 16/100\n",
      "62/62 [==============================] - 108s 2s/step - loss: 0.0287 - acc: 0.9901\n",
      "Epoch 17/100\n",
      "62/62 [==============================] - 107s 2s/step - loss: 0.0231 - acc: 0.9917\n",
      "Epoch 18/100\n",
      "62/62 [==============================] - 107s 2s/step - loss: 0.0246 - acc: 0.9909\n",
      "Epoch 19/100\n",
      "62/62 [==============================] - 107s 2s/step - loss: 0.0207 - acc: 0.9913\n",
      "Epoch 20/100\n",
      "62/62 [==============================] - 106s 2s/step - loss: 0.0215 - acc: 0.9919\n",
      "Epoch 21/100\n",
      "62/62 [==============================] - 107s 2s/step - loss: 0.0749 - acc: 0.9740\n",
      "Epoch 22/100\n",
      "62/62 [==============================] - 108s 2s/step - loss: 0.0355 - acc: 0.9882\n",
      "Epoch 23/100\n",
      "62/62 [==============================] - 107s 2s/step - loss: 0.0203 - acc: 0.9929\n",
      "Epoch 24/100\n",
      "62/62 [==============================] - 106s 2s/step - loss: 0.0200 - acc: 0.9935\n",
      "Epoch 25/100\n",
      "62/62 [==============================] - 106s 2s/step - loss: 0.0183 - acc: 0.9930\n",
      "Epoch 26/100\n",
      "62/62 [==============================] - 106s 2s/step - loss: 0.0195 - acc: 0.9922\n",
      "Epoch 27/100\n",
      "62/62 [==============================] - 106s 2s/step - loss: 0.0178 - acc: 0.9926\n",
      "Epoch 28/100\n",
      "62/62 [==============================] - 106s 2s/step - loss: 0.0161 - acc: 0.9932\n",
      "Epoch 29/100\n",
      "62/62 [==============================] - 106s 2s/step - loss: 0.0168 - acc: 0.9941\n",
      "Epoch 30/100\n",
      "62/62 [==============================] - 106s 2s/step - loss: 0.0177 - acc: 0.9932\n",
      "Epoch 31/100\n",
      "62/62 [==============================] - 106s 2s/step - loss: 1.7136 - acc: 0.4459\n",
      "Epoch 32/100\n",
      "62/62 [==============================] - 106s 2s/step - loss: 1.8373 - acc: 0.2527\n",
      "Epoch 33/100\n",
      "62/62 [==============================] - 108s 2s/step - loss: 1.5463 - acc: 0.3998\n",
      "Epoch 34/100\n",
      "62/62 [==============================] - 109s 2s/step - loss: 0.8828 - acc: 0.6816\n",
      "Epoch 35/100\n",
      "62/62 [==============================] - 110s 2s/step - loss: 0.3414 - acc: 0.8858\n",
      "Epoch 36/100\n",
      "62/62 [==============================] - 110s 2s/step - loss: 0.1784 - acc: 0.9377\n",
      "Epoch 37/100\n",
      "62/62 [==============================] - 110s 2s/step - loss: 0.1114 - acc: 0.9617\n",
      "Epoch 38/100\n",
      "62/62 [==============================] - 109s 2s/step - loss: 0.0801 - acc: 0.9732\n",
      "Epoch 39/100\n",
      "62/62 [==============================] - 109s 2s/step - loss: 0.0522 - acc: 0.9817\n",
      "Epoch 40/100\n",
      "62/62 [==============================] - 109s 2s/step - loss: 0.0532 - acc: 0.9816\n",
      "Epoch 41/100\n",
      "62/62 [==============================] - 109s 2s/step - loss: 0.0286 - acc: 0.9911\n",
      "Epoch 42/100\n",
      "62/62 [==============================] - 109s 2s/step - loss: 0.0374 - acc: 0.9866\n",
      "Epoch 43/100\n",
      "62/62 [==============================] - 108s 2s/step - loss: 0.0230 - acc: 0.9919\n",
      "Epoch 44/100\n",
      "62/62 [==============================] - 107s 2s/step - loss: 0.0250 - acc: 0.9916\n",
      "Epoch 45/100\n",
      "62/62 [==============================] - 107s 2s/step - loss: 0.0212 - acc: 0.9927\n",
      "Epoch 46/100\n",
      "62/62 [==============================] - 107s 2s/step - loss: 0.0224 - acc: 0.9911\n",
      "Epoch 47/100\n",
      "62/62 [==============================] - 107s 2s/step - loss: 0.0219 - acc: 0.9917\n",
      "Epoch 48/100\n",
      "62/62 [==============================] - 107s 2s/step - loss: 0.0340 - acc: 0.9874\n",
      "Epoch 49/100\n",
      "62/62 [==============================] - 107s 2s/step - loss: 0.0267 - acc: 0.9913\n",
      "Epoch 50/100\n",
      "62/62 [==============================] - 108s 2s/step - loss: 0.3980 - acc: 0.8815\n",
      "Epoch 51/100\n",
      "62/62 [==============================] - 110s 2s/step - loss: 0.0728 - acc: 0.9767\n",
      "Epoch 52/100\n",
      "62/62 [==============================] - 109s 2s/step - loss: 0.0336 - acc: 0.9891\n",
      "Epoch 53/100\n",
      "62/62 [==============================] - 108s 2s/step - loss: 0.0233 - acc: 0.9917\n",
      "Epoch 54/100\n",
      "62/62 [==============================] - 108s 2s/step - loss: 0.0222 - acc: 0.9905\n",
      "Epoch 55/100\n",
      "62/62 [==============================] - 108s 2s/step - loss: 0.0175 - acc: 0.9932\n",
      "Epoch 56/100\n",
      "62/62 [==============================] - 107s 2s/step - loss: 0.0180 - acc: 0.9932\n",
      "Epoch 57/100\n",
      "62/62 [==============================] - 106s 2s/step - loss: 0.0178 - acc: 0.9929\n",
      "Epoch 58/100\n",
      "62/62 [==============================] - 106s 2s/step - loss: 0.0180 - acc: 0.9932\n",
      "Epoch 59/100\n",
      "62/62 [==============================] - 106s 2s/step - loss: 0.0147 - acc: 0.9945\n",
      "Epoch 60/100\n",
      "62/62 [==============================] - 106s 2s/step - loss: 0.0150 - acc: 0.9943\n",
      "Epoch 61/100\n",
      "62/62 [==============================] - 106s 2s/step - loss: 0.0156 - acc: 0.9937\n",
      "Epoch 62/100\n",
      "62/62 [==============================] - 106s 2s/step - loss: 0.0149 - acc: 0.9937\n",
      "Epoch 63/100\n",
      "62/62 [==============================] - 105s 2s/step - loss: 0.0137 - acc: 0.9943\n",
      "Epoch 64/100\n",
      "62/62 [==============================] - 107s 2s/step - loss: 0.0141 - acc: 0.9945\n",
      "Epoch 65/100\n",
      "62/62 [==============================] - 106s 2s/step - loss: 0.0152 - acc: 0.9940\n",
      "Epoch 66/100\n",
      "62/62 [==============================] - 105s 2s/step - loss: 0.0133 - acc: 0.9945\n",
      "Epoch 67/100\n",
      "62/62 [==============================] - 106s 2s/step - loss: 0.0134 - acc: 0.9942\n",
      "Epoch 68/100\n",
      "62/62 [==============================] - 105s 2s/step - loss: 0.0123 - acc: 0.9946\n",
      "Epoch 69/100\n",
      "62/62 [==============================] - 105s 2s/step - loss: 0.0132 - acc: 0.9955\n",
      "Epoch 70/100\n",
      "62/62 [==============================] - 105s 2s/step - loss: 0.0132 - acc: 0.9940\n",
      "Epoch 71/100\n",
      "62/62 [==============================] - 104s 2s/step - loss: 0.0131 - acc: 0.9945\n",
      "Epoch 72/100\n",
      "62/62 [==============================] - 104s 2s/step - loss: 0.0139 - acc: 0.9942\n",
      "Epoch 73/100\n",
      "62/62 [==============================] - 104s 2s/step - loss: 0.0134 - acc: 0.9943\n",
      "Epoch 74/100\n",
      "62/62 [==============================] - 104s 2s/step - loss: 0.0127 - acc: 0.9951\n",
      "Epoch 75/100\n",
      "62/62 [==============================] - 104s 2s/step - loss: 0.0126 - acc: 0.9946\n",
      "Epoch 76/100\n",
      "62/62 [==============================] - 104s 2s/step - loss: 0.0131 - acc: 0.9948\n",
      "Epoch 77/100\n",
      "62/62 [==============================] - 104s 2s/step - loss: 0.0127 - acc: 0.9945\n",
      "Epoch 78/100\n",
      "62/62 [==============================] - 104s 2s/step - loss: 0.0128 - acc: 0.9945\n",
      "Epoch 79/100\n",
      "62/62 [==============================] - 104s 2s/step - loss: 0.0136 - acc: 0.9943\n",
      "Epoch 80/100\n",
      "62/62 [==============================] - 104s 2s/step - loss: 0.0123 - acc: 0.9943\n",
      "Epoch 81/100\n",
      "62/62 [==============================] - 104s 2s/step - loss: 0.0125 - acc: 0.9945\n",
      "Epoch 82/100\n",
      "62/62 [==============================] - 105s 2s/step - loss: 0.0130 - acc: 0.9950\n",
      "Epoch 83/100\n",
      "62/62 [==============================] - 106s 2s/step - loss: 0.0163 - acc: 0.9943\n",
      "Epoch 84/100\n",
      "62/62 [==============================] - 106s 2s/step - loss: 0.0123 - acc: 0.9953\n",
      "Epoch 85/100\n",
      "62/62 [==============================] - 105s 2s/step - loss: 0.0121 - acc: 0.9945\n",
      "Epoch 86/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62/62 [==============================] - 105s 2s/step - loss: 0.0127 - acc: 0.9946\n",
      "Epoch 87/100\n",
      "62/62 [==============================] - 105s 2s/step - loss: 0.0137 - acc: 0.9948\n",
      "Epoch 88/100\n",
      "62/62 [==============================] - 105s 2s/step - loss: 0.0121 - acc: 0.9948\n",
      "Epoch 89/100\n",
      "62/62 [==============================] - 107s 2s/step - loss: 0.0661 - acc: 0.9790\n",
      "Epoch 90/100\n",
      "62/62 [==============================] - 108s 2s/step - loss: 0.0154 - acc: 0.9948\n",
      "Epoch 91/100\n",
      "62/62 [==============================] - 106s 2s/step - loss: 0.0137 - acc: 0.9945\n",
      "Epoch 92/100\n",
      "62/62 [==============================] - 107s 2s/step - loss: 0.0132 - acc: 0.9940\n",
      "Epoch 93/100\n",
      "62/62 [==============================] - 106s 2s/step - loss: 0.0126 - acc: 0.9950\n",
      "Epoch 94/100\n",
      "62/62 [==============================] - 106s 2s/step - loss: 0.0134 - acc: 0.9940\n",
      "Epoch 95/100\n",
      "62/62 [==============================] - 106s 2s/step - loss: 0.0126 - acc: 0.9946\n",
      "Epoch 96/100\n",
      "62/62 [==============================] - 106s 2s/step - loss: 0.0132 - acc: 0.9946\n",
      "Epoch 97/100\n",
      "62/62 [==============================] - 106s 2s/step - loss: 0.0128 - acc: 0.9943\n",
      "Epoch 98/100\n",
      "62/62 [==============================] - 106s 2s/step - loss: 0.0128 - acc: 0.9946\n",
      "Epoch 99/100\n",
      "62/62 [==============================] - 105s 2s/step - loss: 0.0116 - acc: 0.9948\n",
      "Epoch 100/100\n",
      "62/62 [==============================] - 105s 2s/step - loss: 0.0125 - acc: 0.9953\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f78f739bb00>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MODEL_NAME = \"model_vgg16_domrock\"\n",
    "\n",
    "if not os.path.isdir('/media/matheusmortatti/External/document-classifier/logs/' + MODEL_NAME):\n",
    "    os.mkdir('/media/matheusmortatti/External/document-classifier/logs/' + MODEL_NAME)\n",
    "\n",
    "unique_folder = str(current_milli_time())\n",
    "os.mkdir('/media/matheusmortatti/External/document-classifier/logs/' + MODEL_NAME + '/' + unique_folder)\n",
    "\n",
    "tbCallback = keras.callbacks.TensorBoard(log_dir='/media/matheusmortatti/External/document-classifier/logs/' + MODEL_NAME + '/' + unique_folder, histogram_freq=0,  \n",
    "          write_graph=True, write_images=True)\n",
    "\n",
    "model.fit_generator(generator(x_train, y_train),\n",
    "          steps_per_epoch=x_train.shape[0] // 100,\n",
    "          epochs=EPOCHS,\n",
    "          verbose=1,\n",
    "          callbacks=[tbCallback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# SAVE MODEL STRUCTURE AND WEIGHTS\n",
    "#\n",
    "\n",
    "def save_model(model):\n",
    "    model_json = model.to_json()\n",
    "    with open(\"/media/matheusmortatti/External/document-classifier/models/\" + MODEL_NAME + \".json\", \"w\") as json_file:\n",
    "        json_file.write(model_json)\n",
    "    # serialize weights to HDF5\n",
    "    model.save_weights(\"/media/matheusmortatti/External/document-classifier/weights/\" + MODEL_NAME + \".h5\")\n",
    "\n",
    "save_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/matheusmortatti/.local/lib/python3.5/site-packages/skimage/transform/_warps.py:105: UserWarning: The default mode, 'constant', will be changed to 'reflect' in skimage 0.15.\n",
      "  warn(\"The default mode, 'constant', will be changed to 'reflect' in \"\n",
      "/home/matheusmortatti/.local/lib/python3.5/site-packages/skimage/transform/_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-18973dc51ef0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0msp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0mval_input\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreprocess_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m     \u001b[0mval_labels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-647995233c8a>\u001b[0m in \u001b[0;36mpreprocess_image\u001b[0;34m(frame)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;31m# Normalize Pixel Values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mnormalized_frame\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mframe\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m255.0\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;31m# Resize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#\n",
    "# RELOAD VALIDATION DATA IF NECESSARY\n",
    "#\n",
    "\n",
    "val_input = []\n",
    "val_labels = []\n",
    "\n",
    "labels_file = open(DATA_FOLDER + \"/labels_test.txt\")\n",
    "\n",
    "for line in labels_file:\n",
    "    sp = line.split()\n",
    "    \n",
    "    val_input.append(preprocess_image(imread(sp[0])))\n",
    "    val_labels.append(int(sp[1]))\n",
    "\n",
    "x_val = np.asarray(val_input)\n",
    "y_true = np.asarray(val_labels)\n",
    "    \n",
    "labels_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict Validation Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(x_val)\n",
    "y_pred = np.argmax(y_pred, axis=1)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot Confusion Matrix and Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_text = [\"Balancete\", \"Balanco\", \"Contas\", \"DRE\", \"Luz A\", \"Luz B\", \"Nota Fiscal\"]\n",
    "y_true = np.asarray(val_labels)\n",
    "\n",
    "plot_confusion_matrix(confusion_matrix(y_true, y_pred), labels_text)\n",
    "print(classification_report(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
