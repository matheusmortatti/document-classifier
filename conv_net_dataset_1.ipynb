{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install scikit-image --user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import keras\n",
    "import numpy as np\n",
    "import random\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, MaxPooling2D, Flatten\n",
    "from keras.models import model_from_json\n",
    "\n",
    "from skimage import transform\n",
    "from skimage.io import imread\n",
    "from skimage.color import rgb2gray\n",
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    Preprocess image, normalizing and resizing it\n",
    "\n",
    "    :param frame: RGBA frame\n",
    "\"\"\"    \n",
    "def preprocess_image(frame):\n",
    "    \n",
    "    # Normalize Pixel Values\n",
    "    normalized_frame = frame/255.0 - 0.5\n",
    "    \n",
    "    # Resize\n",
    "    preprocessed_frame = transform.resize(normalized_frame, IMAGE_PP_SIZE)\n",
    "    \n",
    "    return preprocessed_frame\n",
    "\n",
    "\"\"\"\n",
    "    Create 2D label list from 1D list\n",
    "    \n",
    "    :param labels: 1D label list\n",
    "\"\"\"\n",
    "\n",
    "def make_labels(labels):\n",
    "    np_labels = np.zeros((len(labels), 16))\n",
    "    \n",
    "    for i in range(len(labels)):\n",
    "        np_labels[i, labels[i]] = 1\n",
    "    \n",
    "    return np_labels\n",
    "\n",
    "def file_len(fname):\n",
    "    with open(fname) as f:\n",
    "        for i, l in enumerate(f):\n",
    "            pass\n",
    "    return i + 1\n",
    "\n",
    "def choices(l, k=1):\n",
    "    new_list = []\n",
    "    for i in range(k):\n",
    "        new_list.append(random.choice(l))\n",
    "    return new_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Globals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_PP_SIZE = [150, 150]\n",
    "EPOCHS = 1\n",
    "BATCH_SIZE = 100\n",
    "TRAIN_STEP = 1000\n",
    "VAL_SIZE = 100\n",
    "\n",
    "RELOAD_MODEL = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Model if it Exists, Otherwise Recreate it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "if RELOAD_MODEL:\n",
    "    try:\n",
    "        json_file = open('model.json', 'r')\n",
    "        loaded_model_json = json_file.read()\n",
    "        json_file.close()\n",
    "        model = model_from_json(loaded_model_json)\n",
    "        # load weights into new model\n",
    "        model.load_weights(\"model.h5\")\n",
    "    except FileNotFoundError:\n",
    "\n",
    "        model = Sequential()\n",
    "        model.add(Conv2D(20, kernel_size=(7, 7), strides=(1, 1),\n",
    "                         activation='relu',\n",
    "                         input_shape=(IMAGE_PP_SIZE[0], IMAGE_PP_SIZE[1], 1)))\n",
    "        model.add(MaxPooling2D(pool_size=(4, 4), strides=(1, 1)))\n",
    "        model.add(Conv2D(50, kernel_size = (5, 5), activation='relu'))\n",
    "        model.add(MaxPooling2D(pool_size=(4, 4)))\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(1000, activation='relu'))\n",
    "        model.add(Dense(1000, activation='relu'))\n",
    "        model.add(Dense(16, activation='softmax'))\n",
    "else:\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(20, kernel_size=(7, 7), strides=(1, 1),\n",
    "                     activation='relu',\n",
    "                     input_shape=(IMAGE_PP_SIZE[0], IMAGE_PP_SIZE[1], 1)))\n",
    "    model.add(MaxPooling2D(pool_size=(4, 4), strides=(1, 1)))\n",
    "    model.add(Conv2D(50, kernel_size = (5, 5), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(4, 4)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(1000, activation='relu'))\n",
    "    model.add(Dense(1000, activation='relu'))\n",
    "    model.add(Dense(16, activation='softmax'))\n",
    "\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.SGD(lr=0.01),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/matheusmortatti/.local/lib/python3.5/site-packages/skimage/transform/_warps.py:105: UserWarning: The default mode, 'constant', will be changed to 'reflect' in skimage 0.15.\n",
      "  warn(\"The default mode, 'constant', will be changed to 'reflect' in \"\n",
      "/home/matheusmortatti/.local/lib/python3.5/site-packages/skimage/transform/_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1000 samples, validate on 100 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s 5ms/step - loss: 0.4828 - acc: 0.8640 - val_loss: 0.6091 - val_acc: 0.8000\n",
      "trained: 1000 / 320000\n",
      "Train on 1000 samples, validate on 100 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4994 - acc: 0.8510 - val_loss: 0.7580 - val_acc: 0.7900\n",
      "trained: 2000 / 320000\n",
      "Train on 1000 samples, validate on 100 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4621 - acc: 0.8670 - val_loss: 0.7548 - val_acc: 0.7600\n",
      "trained: 3000 / 320000\n",
      "Train on 1000 samples, validate on 100 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.4665 - acc: 0.8550 - val_loss: 0.6681 - val_acc: 0.8300\n",
      "trained: 4000 / 320000\n",
      "Train on 1000 samples, validate on 100 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.4081 - acc: 0.8730 - val_loss: 0.7587 - val_acc: 0.7600\n",
      "trained: 5000 / 320000\n",
      "Train on 1000 samples, validate on 100 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4511 - acc: 0.8720 - val_loss: 0.8306 - val_acc: 0.7300\n",
      "trained: 6000 / 320000\n",
      "Train on 1000 samples, validate on 100 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4355 - acc: 0.8760 - val_loss: 0.5537 - val_acc: 0.8400\n",
      "trained: 7000 / 320000\n",
      "Train on 1000 samples, validate on 100 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.4909 - acc: 0.8590 - val_loss: 0.9171 - val_acc: 0.7500\n",
      "trained: 8000 / 320000\n",
      "Train on 1000 samples, validate on 100 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4358 - acc: 0.8760 - val_loss: 0.6952 - val_acc: 0.8000\n",
      "trained: 9000 / 320000\n",
      "Train on 1000 samples, validate on 100 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.4651 - acc: 0.8600 - val_loss: 0.8029 - val_acc: 0.7400\n",
      "trained: 10000 / 320000\n",
      "Train on 1000 samples, validate on 100 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4817 - acc: 0.8580 - val_loss: 0.6614 - val_acc: 0.8100\n",
      "trained: 11000 / 320000\n",
      "Train on 1000 samples, validate on 100 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.4277 - acc: 0.8660 - val_loss: 0.5052 - val_acc: 0.8100\n",
      "trained: 12000 / 320000\n",
      "Train on 1000 samples, validate on 100 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4315 - acc: 0.8660 - val_loss: 0.7344 - val_acc: 0.7800\n",
      "trained: 13000 / 320000\n",
      "Train on 1000 samples, validate on 100 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.4324 - acc: 0.8750 - val_loss: 0.7459 - val_acc: 0.7400\n",
      "trained: 14000 / 320000\n",
      "Train on 1000 samples, validate on 100 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.4089 - acc: 0.8820 - val_loss: 0.7707 - val_acc: 0.7900\n",
      "trained: 15000 / 320000\n",
      "Train on 1000 samples, validate on 100 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4321 - acc: 0.8700 - val_loss: 0.6869 - val_acc: 0.8300\n",
      "trained: 16000 / 320000\n",
      "Train on 1000 samples, validate on 100 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3630 - acc: 0.8910 - val_loss: 0.6726 - val_acc: 0.8300\n",
      "trained: 17000 / 320000\n",
      "Train on 1000 samples, validate on 100 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3976 - acc: 0.8910 - val_loss: 0.4960 - val_acc: 0.8600\n",
      "trained: 18000 / 320000\n",
      "Train on 1000 samples, validate on 100 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3642 - acc: 0.8890 - val_loss: 0.5999 - val_acc: 0.8300\n",
      "trained: 19000 / 320000\n",
      "Train on 1000 samples, validate on 100 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.4798 - acc: 0.8520 - val_loss: 1.0194 - val_acc: 0.7000\n",
      "trained: 20000 / 320000\n",
      "Train on 1000 samples, validate on 100 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3825 - acc: 0.8890 - val_loss: 0.5944 - val_acc: 0.8500\n",
      "trained: 21000 / 320000\n",
      "Train on 1000 samples, validate on 100 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3991 - acc: 0.8820 - val_loss: 0.5583 - val_acc: 0.8500\n",
      "trained: 22000 / 320000\n",
      "Train on 1000 samples, validate on 100 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4384 - acc: 0.8690 - val_loss: 0.7685 - val_acc: 0.8200\n",
      "trained: 23000 / 320000\n",
      "Train on 1000 samples, validate on 100 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3631 - acc: 0.8990 - val_loss: 0.3967 - val_acc: 0.8700\n",
      "trained: 24000 / 320000\n",
      "Train on 1000 samples, validate on 100 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3489 - acc: 0.8930 - val_loss: 0.7751 - val_acc: 0.7800\n",
      "trained: 25000 / 320000\n",
      "Train on 1000 samples, validate on 100 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4479 - acc: 0.8640 - val_loss: 0.7882 - val_acc: 0.7500\n",
      "trained: 26000 / 320000\n",
      "Train on 1000 samples, validate on 100 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3590 - acc: 0.8890 - val_loss: 0.6281 - val_acc: 0.8000\n",
      "trained: 27000 / 320000\n",
      "Train on 1000 samples, validate on 100 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3580 - acc: 0.8940 - val_loss: 0.6859 - val_acc: 0.8300\n",
      "trained: 28000 / 320000\n",
      "Train on 1000 samples, validate on 100 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3823 - acc: 0.8930 - val_loss: 0.9005 - val_acc: 0.7500\n",
      "trained: 29000 / 320000\n",
      "Train on 1000 samples, validate on 100 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.4167 - acc: 0.8690 - val_loss: 0.7218 - val_acc: 0.7800\n",
      "trained: 30000 / 320000\n",
      "Train on 1000 samples, validate on 100 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4093 - acc: 0.8800 - val_loss: 0.9706 - val_acc: 0.7500\n",
      "trained: 31000 / 320000\n",
      "Train on 1000 samples, validate on 100 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3432 - acc: 0.9020 - val_loss: 0.5325 - val_acc: 0.8500\n",
      "trained: 32000 / 320000\n",
      "Train on 1000 samples, validate on 100 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3519 - acc: 0.8980 - val_loss: 0.4418 - val_acc: 0.8900\n",
      "trained: 33000 / 320000\n",
      "Train on 1000 samples, validate on 100 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3492 - acc: 0.8830 - val_loss: 0.7605 - val_acc: 0.8300\n",
      "trained: 34000 / 320000\n",
      "Train on 1000 samples, validate on 100 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3471 - acc: 0.8910 - val_loss: 0.7144 - val_acc: 0.7500\n",
      "trained: 35000 / 320000\n",
      "Train on 1000 samples, validate on 100 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4268 - acc: 0.8760 - val_loss: 0.4642 - val_acc: 0.8600\n",
      "trained: 36000 / 320000\n",
      "Train on 1000 samples, validate on 100 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4103 - acc: 0.8830 - val_loss: 0.7892 - val_acc: 0.7900\n",
      "trained: 37000 / 320000\n",
      "Train on 1000 samples, validate on 100 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3833 - acc: 0.8860 - val_loss: 0.7053 - val_acc: 0.7500\n",
      "trained: 38000 / 320000\n",
      "Train on 1000 samples, validate on 100 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3294 - acc: 0.9050 - val_loss: 0.8431 - val_acc: 0.7700\n",
      "trained: 39000 / 320000\n",
      "Train on 1000 samples, validate on 100 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3753 - acc: 0.8910 - val_loss: 0.5003 - val_acc: 0.8300\n",
      "trained: 40000 / 320000\n",
      "Train on 1000 samples, validate on 100 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3196 - acc: 0.8960 - val_loss: 0.5787 - val_acc: 0.8300\n",
      "trained: 41000 / 320000\n",
      "Train on 1000 samples, validate on 100 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3373 - acc: 0.8960 - val_loss: 0.3857 - val_acc: 0.8800\n",
      "trained: 42000 / 320000\n",
      "Train on 1000 samples, validate on 100 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3708 - acc: 0.8800 - val_loss: 0.6806 - val_acc: 0.7600\n",
      "trained: 43000 / 320000\n",
      "Train on 1000 samples, validate on 100 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3208 - acc: 0.9060 - val_loss: 0.8370 - val_acc: 0.7400\n",
      "trained: 44000 / 320000\n",
      "Train on 1000 samples, validate on 100 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3931 - acc: 0.8780 - val_loss: 0.4336 - val_acc: 0.8700\n",
      "trained: 45000 / 320000\n",
      "Train on 1000 samples, validate on 100 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3542 - acc: 0.8990 - val_loss: 0.9351 - val_acc: 0.8000\n",
      "trained: 46000 / 320000\n",
      "Train on 1000 samples, validate on 100 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3340 - acc: 0.9040 - val_loss: 0.7595 - val_acc: 0.7600\n",
      "trained: 47000 / 320000\n",
      "Train on 1000 samples, validate on 100 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3581 - acc: 0.8970 - val_loss: 0.7991 - val_acc: 0.7200\n",
      "trained: 48000 / 320000\n",
      "Train on 1000 samples, validate on 100 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3165 - acc: 0.9000 - val_loss: 0.5698 - val_acc: 0.8000\n",
      "trained: 49000 / 320000\n",
      "Train on 1000 samples, validate on 100 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3266 - acc: 0.9090 - val_loss: 0.7443 - val_acc: 0.8100\n",
      "trained: 50000 / 320000\n",
      "Train on 1000 samples, validate on 100 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3647 - acc: 0.8960 - val_loss: 1.0273 - val_acc: 0.7200\n",
      "trained: 51000 / 320000\n",
      "Train on 1000 samples, validate on 100 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3464 - acc: 0.8990 - val_loss: 0.8601 - val_acc: 0.7800\n",
      "trained: 52000 / 320000\n",
      "Train on 1000 samples, validate on 100 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3352 - acc: 0.9000 - val_loss: 0.5263 - val_acc: 0.8500\n",
      "trained: 53000 / 320000\n",
      "Train on 1000 samples, validate on 100 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3248 - acc: 0.8940 - val_loss: 0.7724 - val_acc: 0.7700\n",
      "trained: 54000 / 320000\n",
      "Train on 1000 samples, validate on 100 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3016 - acc: 0.9160 - val_loss: 0.8324 - val_acc: 0.8200\n",
      "trained: 55000 / 320000\n",
      "Train on 1000 samples, validate on 100 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3397 - acc: 0.9000 - val_loss: 0.3359 - val_acc: 0.8700\n",
      "trained: 56000 / 320000\n",
      "Train on 1000 samples, validate on 100 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3370 - acc: 0.9130 - val_loss: 0.7737 - val_acc: 0.8300\n",
      "trained: 57000 / 320000\n",
      "Train on 1000 samples, validate on 100 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3004 - acc: 0.9190 - val_loss: 0.5707 - val_acc: 0.8500\n",
      "trained: 58000 / 320000\n",
      "Train on 1000 samples, validate on 100 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3404 - acc: 0.8990 - val_loss: 0.7573 - val_acc: 0.7500\n",
      "trained: 59000 / 320000\n",
      "Train on 1000 samples, validate on 100 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3234 - acc: 0.8980 - val_loss: 0.5286 - val_acc: 0.8600\n",
      "trained: 60000 / 320000\n",
      "Train on 1000 samples, validate on 100 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3685 - acc: 0.8800 - val_loss: 1.0715 - val_acc: 0.6900\n",
      "trained: 61000 / 320000\n",
      "Train on 1000 samples, validate on 100 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3392 - acc: 0.8990 - val_loss: 0.5682 - val_acc: 0.8400\n",
      "trained: 62000 / 320000\n",
      "Train on 1000 samples, validate on 100 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3119 - acc: 0.9050 - val_loss: 0.7286 - val_acc: 0.8000\n",
      "trained: 63000 / 320000\n",
      "Train on 1000 samples, validate on 100 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3115 - acc: 0.9040 - val_loss: 0.5134 - val_acc: 0.7900\n",
      "trained: 64000 / 320000\n",
      "Train on 1000 samples, validate on 100 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.2711 - acc: 0.9200 - val_loss: 0.6173 - val_acc: 0.8300\n",
      "trained: 65000 / 320000\n",
      "Train on 1000 samples, validate on 100 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.2661 - acc: 0.9260 - val_loss: 0.7326 - val_acc: 0.8300\n",
      "trained: 66000 / 320000\n",
      "Train on 1000 samples, validate on 100 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.2956 - acc: 0.9110 - val_loss: 0.6001 - val_acc: 0.7900\n",
      "trained: 67000 / 320000\n",
      "Train on 1000 samples, validate on 100 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.2832 - acc: 0.9100 - val_loss: 0.8238 - val_acc: 0.8100\n",
      "trained: 68000 / 320000\n",
      "Train on 1000 samples, validate on 100 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3047 - acc: 0.9110 - val_loss: 0.8671 - val_acc: 0.7600\n",
      "trained: 69000 / 320000\n",
      "Train on 1000 samples, validate on 100 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.2981 - acc: 0.9080 - val_loss: 0.5343 - val_acc: 0.8200\n",
      "trained: 70000 / 320000\n",
      "Train on 1000 samples, validate on 100 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3010 - acc: 0.9050 - val_loss: 0.7182 - val_acc: 0.7500\n",
      "trained: 71000 / 320000\n",
      "Train on 1000 samples, validate on 100 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.2286 - acc: 0.9300 - val_loss: 0.3098 - val_acc: 0.8800\n",
      "trained: 72000 / 320000\n",
      "Train on 1000 samples, validate on 100 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.2940 - acc: 0.9090 - val_loss: 0.7376 - val_acc: 0.7900\n",
      "trained: 73000 / 320000\n",
      "Train on 1000 samples, validate on 100 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.2732 - acc: 0.9220 - val_loss: 0.7144 - val_acc: 0.8000\n",
      "trained: 74000 / 320000\n",
      "Train on 1000 samples, validate on 100 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3028 - acc: 0.9220 - val_loss: 0.5617 - val_acc: 0.8400\n",
      "trained: 75000 / 320000\n",
      "Train on 1000 samples, validate on 100 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.2713 - acc: 0.9220 - val_loss: 0.5861 - val_acc: 0.7700\n",
      "trained: 76000 / 320000\n",
      "Train on 1000 samples, validate on 100 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.2743 - acc: 0.9110 - val_loss: 0.6295 - val_acc: 0.8600\n",
      "trained: 77000 / 320000\n",
      "Train on 1000 samples, validate on 100 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3039 - acc: 0.8990 - val_loss: 0.5658 - val_acc: 0.8300\n",
      "trained: 78000 / 320000\n",
      "Train on 1000 samples, validate on 100 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.2831 - acc: 0.9220 - val_loss: 0.6056 - val_acc: 0.7900\n",
      "trained: 79000 / 320000\n",
      "Train on 1000 samples, validate on 100 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.2805 - acc: 0.9260 - val_loss: 0.6534 - val_acc: 0.8300\n",
      "trained: 80000 / 320000\n",
      "Train on 1000 samples, validate on 100 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3210 - acc: 0.9050 - val_loss: 0.8635 - val_acc: 0.7900\n",
      "trained: 81000 / 320000\n",
      "Train on 1000 samples, validate on 100 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.2665 - acc: 0.9250 - val_loss: 0.5082 - val_acc: 0.8600\n",
      "trained: 82000 / 320000\n",
      "Train on 1000 samples, validate on 100 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.2523 - acc: 0.9250 - val_loss: 0.8044 - val_acc: 0.7800\n",
      "trained: 83000 / 320000\n",
      "Train on 1000 samples, validate on 100 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.2910 - acc: 0.9040 - val_loss: 0.8687 - val_acc: 0.8100\n",
      "trained: 84000 / 320000\n",
      "Train on 1000 samples, validate on 100 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.2901 - acc: 0.9070 - val_loss: 0.7456 - val_acc: 0.7600\n",
      "trained: 85000 / 320000\n",
      "Train on 1000 samples, validate on 100 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.2908 - acc: 0.9150 - val_loss: 0.7254 - val_acc: 0.7600\n",
      "trained: 86000 / 320000\n",
      "Train on 1000 samples, validate on 100 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.2469 - acc: 0.9320 - val_loss: 0.7798 - val_acc: 0.7900\n",
      "trained: 87000 / 320000\n",
      "Train on 1000 samples, validate on 100 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.2696 - acc: 0.9280 - val_loss: 0.4721 - val_acc: 0.8700\n",
      "trained: 88000 / 320000\n",
      "Train on 1000 samples, validate on 100 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.2919 - acc: 0.9150 - val_loss: 0.6029 - val_acc: 0.8600\n",
      "trained: 89000 / 320000\n",
      "Train on 1000 samples, validate on 100 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.2422 - acc: 0.9260 - val_loss: 0.5993 - val_acc: 0.7700\n",
      "trained: 90000 / 320000\n",
      "Train on 1000 samples, validate on 100 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.2381 - acc: 0.9330 - val_loss: 0.7919 - val_acc: 0.7600\n",
      "trained: 91000 / 320000\n",
      "Train on 1000 samples, validate on 100 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.2601 - acc: 0.9170 - val_loss: 0.7143 - val_acc: 0.8400\n",
      "trained: 92000 / 320000\n",
      "Train on 1000 samples, validate on 100 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.2122 - acc: 0.9410 - val_loss: 0.5901 - val_acc: 0.8500\n",
      "trained: 93000 / 320000\n",
      "Train on 1000 samples, validate on 100 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.2435 - acc: 0.9240 - val_loss: 0.8325 - val_acc: 0.7900\n",
      "trained: 94000 / 320000\n",
      "Train on 1000 samples, validate on 100 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3037 - acc: 0.9100 - val_loss: 0.6935 - val_acc: 0.8400\n",
      "trained: 95000 / 320000\n",
      "Train on 1000 samples, validate on 100 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.2661 - acc: 0.9200 - val_loss: 0.5365 - val_acc: 0.8500\n",
      "trained: 96000 / 320000\n",
      "Train on 1000 samples, validate on 100 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.2470 - acc: 0.9230 - val_loss: 0.9879 - val_acc: 0.7600\n",
      "trained: 97000 / 320000\n",
      "Train on 1000 samples, validate on 100 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.2539 - acc: 0.9270 - val_loss: 0.7203 - val_acc: 0.8300\n",
      "trained: 98000 / 320000\n",
      "Train on 1000 samples, validate on 100 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.2107 - acc: 0.9370 - val_loss: 0.4534 - val_acc: 0.8700\n",
      "trained: 99000 / 320000\n",
      "Train on 1000 samples, validate on 100 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.2409 - acc: 0.9260 - val_loss: 0.9612 - val_acc: 0.7300\n",
      "trained: 100000 / 320000\n",
      "Train on 1000 samples, validate on 100 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.2057 - acc: 0.9430 - val_loss: 0.8729 - val_acc: 0.7700\n",
      "trained: 101000 / 320000\n",
      "Train on 1000 samples, validate on 100 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.2379 - acc: 0.9270 - val_loss: 0.3600 - val_acc: 0.9000\n",
      "trained: 102000 / 320000\n",
      "Train on 1000 samples, validate on 100 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.2549 - acc: 0.9170 - val_loss: 0.8741 - val_acc: 0.7500\n",
      "trained: 103000 / 320000\n",
      "Train on 1000 samples, validate on 100 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.2609 - acc: 0.9240 - val_loss: 0.5440 - val_acc: 0.8100\n",
      "trained: 104000 / 320000\n",
      "Train on 1000 samples, validate on 100 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.2542 - acc: 0.9180 - val_loss: 0.6389 - val_acc: 0.8400\n",
      "trained: 105000 / 320000\n",
      "Train on 1000 samples, validate on 100 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.2501 - acc: 0.9350 - val_loss: 0.7115 - val_acc: 0.8300\n",
      "trained: 106000 / 320000\n",
      "Train on 1000 samples, validate on 100 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.2103 - acc: 0.9350 - val_loss: 0.6666 - val_acc: 0.8500\n",
      "trained: 107000 / 320000\n",
      "Train on 1000 samples, validate on 100 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.1996 - acc: 0.9480 - val_loss: 0.6565 - val_acc: 0.8500\n",
      "trained: 108000 / 320000\n",
      "Train on 1000 samples, validate on 100 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.1981 - acc: 0.9380 - val_loss: 0.7342 - val_acc: 0.7700\n",
      "trained: 109000 / 320000\n",
      "Train on 1000 samples, validate on 100 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.2264 - acc: 0.9380 - val_loss: 0.6038 - val_acc: 0.7700\n",
      "trained: 110000 / 320000\n",
      "Train on 1000 samples, validate on 100 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.2045 - acc: 0.9390 - val_loss: 0.7586 - val_acc: 0.7800\n",
      "trained: 111000 / 320000\n",
      "Train on 1000 samples, validate on 100 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.2145 - acc: 0.9360 - val_loss: 0.6415 - val_acc: 0.8800\n",
      "trained: 112000 / 320000\n",
      "Train on 1000 samples, validate on 100 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.2254 - acc: 0.9280 - val_loss: 0.5312 - val_acc: 0.8400\n",
      "trained: 113000 / 320000\n",
      "Train on 1000 samples, validate on 100 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.2003 - acc: 0.9410 - val_loss: 0.8111 - val_acc: 0.7400\n",
      "trained: 114000 / 320000\n",
      "Train on 1000 samples, validate on 100 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.1981 - acc: 0.9440 - val_loss: 0.5489 - val_acc: 0.8300\n",
      "trained: 115000 / 320000\n",
      "Train on 1000 samples, validate on 100 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.1744 - acc: 0.9550 - val_loss: 0.7155 - val_acc: 0.8000\n",
      "trained: 116000 / 320000\n",
      "Train on 1000 samples, validate on 100 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.1703 - acc: 0.9520 - val_loss: 0.8425 - val_acc: 0.8400\n",
      "trained: 117000 / 320000\n",
      "Train on 1000 samples, validate on 100 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.1767 - acc: 0.9570 - val_loss: 0.7157 - val_acc: 0.8200\n",
      "trained: 118000 / 320000\n",
      "Train on 1000 samples, validate on 100 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.2065 - acc: 0.9370 - val_loss: 0.7589 - val_acc: 0.8000\n",
      "trained: 119000 / 320000\n",
      "Train on 1000 samples, validate on 100 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.2043 - acc: 0.9410 - val_loss: 0.6391 - val_acc: 0.8300\n",
      "trained: 120000 / 320000\n",
      "Train on 1000 samples, validate on 100 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.1835 - acc: 0.9450 - val_loss: 0.4184 - val_acc: 0.9100\n",
      "trained: 121000 / 320000\n",
      "Train on 1000 samples, validate on 100 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.2423 - acc: 0.9280 - val_loss: 0.5407 - val_acc: 0.7900\n",
      "trained: 122000 / 320000\n",
      "Train on 1000 samples, validate on 100 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.2120 - acc: 0.9290 - val_loss: 0.6121 - val_acc: 0.8500\n",
      "trained: 123000 / 320000\n",
      "Train on 1000 samples, validate on 100 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.1977 - acc: 0.9410 - val_loss: 0.8227 - val_acc: 0.7800\n",
      "trained: 124000 / 320000\n",
      "Train on 1000 samples, validate on 100 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.1976 - acc: 0.9460 - val_loss: 0.8758 - val_acc: 0.7600\n",
      "trained: 125000 / 320000\n",
      "Train on 1000 samples, validate on 100 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.1793 - acc: 0.9550 - val_loss: 0.8659 - val_acc: 0.7500\n",
      "trained: 126000 / 320000\n",
      "Train on 1000 samples, validate on 100 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.1406 - acc: 0.9640 - val_loss: 0.5828 - val_acc: 0.8500\n",
      "trained: 127000 / 320000\n",
      "Train on 1000 samples, validate on 100 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.1580 - acc: 0.9650 - val_loss: 0.7697 - val_acc: 0.7900\n",
      "trained: 128000 / 320000\n",
      "Train on 1000 samples, validate on 100 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.1583 - acc: 0.9520 - val_loss: 0.6680 - val_acc: 0.8500\n",
      "trained: 129000 / 320000\n",
      "Train on 1000 samples, validate on 100 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.1663 - acc: 0.9520 - val_loss: 0.4451 - val_acc: 0.8500\n",
      "trained: 130000 / 320000\n",
      "Train on 1000 samples, validate on 100 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.1327 - acc: 0.9600 - val_loss: 0.4292 - val_acc: 0.8900\n",
      "trained: 131000 / 320000\n",
      "Train on 1000 samples, validate on 100 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.1701 - acc: 0.9510 - val_loss: 0.7136 - val_acc: 0.8200\n",
      "trained: 132000 / 320000\n",
      "Train on 1000 samples, validate on 100 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.1493 - acc: 0.9620 - val_loss: 0.9042 - val_acc: 0.7800\n",
      "trained: 133000 / 320000\n",
      "Train on 1000 samples, validate on 100 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.1586 - acc: 0.9630 - val_loss: 0.9504 - val_acc: 0.8100\n",
      "trained: 134000 / 320000\n",
      "Train on 1000 samples, validate on 100 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.1928 - acc: 0.9490 - val_loss: 0.8327 - val_acc: 0.7800\n",
      "trained: 135000 / 320000\n",
      "Train on 1000 samples, validate on 100 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.1893 - acc: 0.9530 - val_loss: 0.8017 - val_acc: 0.7700\n",
      "trained: 136000 / 320000\n",
      "Train on 1000 samples, validate on 100 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.1488 - acc: 0.9660 - val_loss: 0.5887 - val_acc: 0.8600\n",
      "trained: 137000 / 320000\n",
      "Train on 1000 samples, validate on 100 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.1303 - acc: 0.9590 - val_loss: 0.6202 - val_acc: 0.8000\n",
      "trained: 138000 / 320000\n",
      "Train on 1000 samples, validate on 100 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.1555 - acc: 0.9570 - val_loss: 0.8279 - val_acc: 0.7700\n",
      "trained: 139000 / 320000\n",
      "Train on 1000 samples, validate on 100 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.5220 - acc: 0.8530 - val_loss: 0.6812 - val_acc: 0.8100\n",
      "trained: 140000 / 320000\n",
      "Train on 1000 samples, validate on 100 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.5031 - acc: 0.8590 - val_loss: 0.7190 - val_acc: 0.8000\n",
      "trained: 141000 / 320000\n",
      "Train on 1000 samples, validate on 100 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.5118 - acc: 0.8360 - val_loss: 0.6695 - val_acc: 0.8400\n",
      "trained: 142000 / 320000\n",
      "Train on 1000 samples, validate on 100 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.5437 - acc: 0.8420 - val_loss: 0.6731 - val_acc: 0.7400\n",
      "trained: 143000 / 320000\n",
      "Train on 1000 samples, validate on 100 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.5775 - acc: 0.8340 - val_loss: 0.4345 - val_acc: 0.8800\n",
      "trained: 144000 / 320000\n",
      "Train on 1000 samples, validate on 100 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4877 - acc: 0.8640 - val_loss: 0.6959 - val_acc: 0.7900\n",
      "trained: 145000 / 320000\n",
      "Train on 1000 samples, validate on 100 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4821 - acc: 0.8600 - val_loss: 0.8058 - val_acc: 0.7200\n",
      "trained: 146000 / 320000\n",
      "Train on 1000 samples, validate on 100 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.5668 - acc: 0.8310 - val_loss: 0.7048 - val_acc: 0.7800\n",
      "trained: 147000 / 320000\n",
      "Train on 1000 samples, validate on 100 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4925 - acc: 0.8460 - val_loss: 0.5774 - val_acc: 0.8100\n",
      "trained: 148000 / 320000\n",
      "Train on 1000 samples, validate on 100 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4565 - acc: 0.8640 - val_loss: 0.5809 - val_acc: 0.8200\n",
      "trained: 149000 / 320000\n",
      "Train on 1000 samples, validate on 100 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.5125 - acc: 0.8560 - val_loss: 0.5627 - val_acc: 0.8500\n",
      "trained: 150000 / 320000\n",
      "Train on 1000 samples, validate on 100 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4852 - acc: 0.8500 - val_loss: 0.6216 - val_acc: 0.7800\n",
      "trained: 151000 / 320000\n",
      "Train on 1000 samples, validate on 100 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.5049 - acc: 0.8410 - val_loss: 0.7822 - val_acc: 0.7700\n",
      "trained: 152000 / 320000\n",
      "Train on 1000 samples, validate on 100 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4953 - acc: 0.8550 - val_loss: 0.6822 - val_acc: 0.8000\n",
      "trained: 153000 / 320000\n",
      "Train on 1000 samples, validate on 100 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4745 - acc: 0.8610 - val_loss: 0.8345 - val_acc: 0.8000\n",
      "trained: 154000 / 320000\n",
      "Train on 1000 samples, validate on 100 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.5108 - acc: 0.8420 - val_loss: 0.7031 - val_acc: 0.7800\n",
      "trained: 155000 / 320000\n",
      "Train on 1000 samples, validate on 100 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4916 - acc: 0.8390 - val_loss: 0.5424 - val_acc: 0.8500\n",
      "trained: 156000 / 320000\n",
      "Train on 1000 samples, validate on 100 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.5543 - acc: 0.8350 - val_loss: 0.6957 - val_acc: 0.8200\n",
      "trained: 157000 / 320000\n",
      "Train on 1000 samples, validate on 100 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4908 - acc: 0.8470 - val_loss: 0.6595 - val_acc: 0.8200\n",
      "trained: 158000 / 320000\n",
      "Train on 1000 samples, validate on 100 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.5768 - acc: 0.8420 - val_loss: 0.6538 - val_acc: 0.7600\n",
      "trained: 159000 / 320000\n",
      "Train on 1000 samples, validate on 100 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.5095 - acc: 0.8480 - val_loss: 0.6524 - val_acc: 0.8200\n",
      "trained: 160000 / 320000\n",
      "Train on 1000 samples, validate on 100 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.5216 - acc: 0.8360 - val_loss: 0.6243 - val_acc: 0.8700\n",
      "trained: 161000 / 320000\n",
      "Train on 1000 samples, validate on 100 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4793 - acc: 0.8640 - val_loss: 0.8144 - val_acc: 0.8200\n",
      "trained: 162000 / 320000\n",
      "Train on 1000 samples, validate on 100 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4428 - acc: 0.8690 - val_loss: 0.6045 - val_acc: 0.8000\n",
      "trained: 163000 / 320000\n",
      "Train on 1000 samples, validate on 100 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4758 - acc: 0.8510 - val_loss: 0.8402 - val_acc: 0.7900\n",
      "trained: 164000 / 320000\n",
      "Train on 1000 samples, validate on 100 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.5155 - acc: 0.8350 - val_loss: 0.6209 - val_acc: 0.8000\n",
      "trained: 165000 / 320000\n",
      "Train on 1000 samples, validate on 100 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4652 - acc: 0.8490 - val_loss: 0.5314 - val_acc: 0.8800\n",
      "trained: 166000 / 320000\n",
      "Train on 1000 samples, validate on 100 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4792 - acc: 0.8540 - val_loss: 0.6000 - val_acc: 0.8200\n",
      "trained: 167000 / 320000\n",
      "Train on 1000 samples, validate on 100 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4642 - acc: 0.8570 - val_loss: 0.8434 - val_acc: 0.7600\n",
      "trained: 168000 / 320000\n",
      "Train on 1000 samples, validate on 100 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.5067 - acc: 0.8430 - val_loss: 0.7526 - val_acc: 0.8000\n",
      "trained: 169000 / 320000\n",
      "Train on 1000 samples, validate on 100 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4742 - acc: 0.8540 - val_loss: 0.4815 - val_acc: 0.8400\n",
      "trained: 170000 / 320000\n",
      "Train on 1000 samples, validate on 100 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4994 - acc: 0.8450 - val_loss: 0.5082 - val_acc: 0.8500\n",
      "trained: 171000 / 320000\n",
      "Train on 1000 samples, validate on 100 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4933 - acc: 0.8470 - val_loss: 0.7992 - val_acc: 0.7700\n",
      "trained: 172000 / 320000\n",
      "Train on 1000 samples, validate on 100 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.5034 - acc: 0.8530 - val_loss: 0.6491 - val_acc: 0.7800\n",
      "trained: 173000 / 320000\n",
      "Train on 1000 samples, validate on 100 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4951 - acc: 0.8650 - val_loss: 0.8504 - val_acc: 0.8000\n",
      "trained: 174000 / 320000\n",
      "Train on 1000 samples, validate on 100 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4746 - acc: 0.8450 - val_loss: 0.6440 - val_acc: 0.8000\n",
      "trained: 175000 / 320000\n",
      "Train on 1000 samples, validate on 100 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4754 - acc: 0.8520 - val_loss: 0.6670 - val_acc: 0.8100\n",
      "trained: 176000 / 320000\n",
      "Train on 1000 samples, validate on 100 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4509 - acc: 0.8770 - val_loss: 0.5908 - val_acc: 0.8100\n",
      "trained: 177000 / 320000\n",
      "Train on 1000 samples, validate on 100 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4817 - acc: 0.8510 - val_loss: 0.6878 - val_acc: 0.8200\n",
      "trained: 178000 / 320000\n",
      "Train on 1000 samples, validate on 100 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4577 - acc: 0.8530 - val_loss: 0.6271 - val_acc: 0.8400\n",
      "trained: 179000 / 320000\n",
      "Train on 1000 samples, validate on 100 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3867 - acc: 0.8870 - val_loss: 0.6451 - val_acc: 0.8300\n",
      "trained: 180000 / 320000\n",
      "Train on 1000 samples, validate on 100 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4474 - acc: 0.8690 - val_loss: 1.0741 - val_acc: 0.7000\n",
      "trained: 181000 / 320000\n",
      "Train on 1000 samples, validate on 100 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4485 - acc: 0.8610 - val_loss: 0.6198 - val_acc: 0.8300\n",
      "trained: 182000 / 320000\n",
      "Train on 1000 samples, validate on 100 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4453 - acc: 0.8640 - val_loss: 0.6123 - val_acc: 0.8100\n",
      "trained: 183000 / 320000\n",
      "Train on 1000 samples, validate on 100 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4265 - acc: 0.8640 - val_loss: 0.7008 - val_acc: 0.8100\n",
      "trained: 184000 / 320000\n",
      "Train on 1000 samples, validate on 100 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4396 - acc: 0.8590 - val_loss: 0.6636 - val_acc: 0.8100\n",
      "trained: 185000 / 320000\n",
      "Train on 1000 samples, validate on 100 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4296 - acc: 0.8760 - val_loss: 0.7720 - val_acc: 0.7200\n",
      "trained: 186000 / 320000\n",
      "Train on 1000 samples, validate on 100 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4821 - acc: 0.8550 - val_loss: 0.7721 - val_acc: 0.7800\n",
      "trained: 187000 / 320000\n",
      "Train on 1000 samples, validate on 100 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4032 - acc: 0.8850 - val_loss: 0.5975 - val_acc: 0.8500\n",
      "trained: 188000 / 320000\n",
      "Train on 1000 samples, validate on 100 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4561 - acc: 0.8630 - val_loss: 0.4390 - val_acc: 0.8700\n",
      "trained: 189000 / 320000\n",
      "Train on 1000 samples, validate on 100 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4221 - acc: 0.8710 - val_loss: 0.4033 - val_acc: 0.8700\n",
      "trained: 190000 / 320000\n",
      "Train on 1000 samples, validate on 100 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4488 - acc: 0.8660 - val_loss: 0.8990 - val_acc: 0.7500\n",
      "trained: 191000 / 320000\n",
      "Train on 1000 samples, validate on 100 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4426 - acc: 0.8540 - val_loss: 0.6364 - val_acc: 0.8200\n",
      "trained: 192000 / 320000\n",
      "Train on 1000 samples, validate on 100 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4078 - acc: 0.8800 - val_loss: 0.6581 - val_acc: 0.8100\n",
      "trained: 193000 / 320000\n",
      "Train on 1000 samples, validate on 100 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4546 - acc: 0.8730 - val_loss: 0.6881 - val_acc: 0.8100\n",
      "trained: 194000 / 320000\n",
      "Train on 1000 samples, validate on 100 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4865 - acc: 0.8570 - val_loss: 0.4972 - val_acc: 0.8700\n",
      "trained: 195000 / 320000\n",
      "Train on 1000 samples, validate on 100 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4865 - acc: 0.8520 - val_loss: 0.7137 - val_acc: 0.8200\n",
      "trained: 196000 / 320000\n",
      "Train on 1000 samples, validate on 100 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4530 - acc: 0.8740 - val_loss: 0.4653 - val_acc: 0.8400\n",
      "trained: 197000 / 320000\n",
      "Train on 1000 samples, validate on 100 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4226 - acc: 0.8680 - val_loss: 0.4152 - val_acc: 0.8700\n",
      "trained: 198000 / 320000\n",
      "Train on 1000 samples, validate on 100 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4555 - acc: 0.8570 - val_loss: 0.8257 - val_acc: 0.7700\n",
      "trained: 199000 / 320000\n",
      "Train on 1000 samples, validate on 100 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4374 - acc: 0.8730 - val_loss: 0.4346 - val_acc: 0.8200\n",
      "trained: 200000 / 320000\n",
      "Train on 1000 samples, validate on 100 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4960 - acc: 0.8510 - val_loss: 0.8867 - val_acc: 0.7300\n",
      "trained: 201000 / 320000\n",
      "Train on 1000 samples, validate on 100 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4365 - acc: 0.8760 - val_loss: 0.6935 - val_acc: 0.8000\n",
      "trained: 202000 / 320000\n",
      "Train on 1000 samples, validate on 100 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4547 - acc: 0.8640 - val_loss: 0.8861 - val_acc: 0.7700\n",
      "trained: 203000 / 320000\n",
      "Train on 1000 samples, validate on 100 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4440 - acc: 0.8520 - val_loss: 0.6630 - val_acc: 0.8100\n",
      "trained: 204000 / 320000\n",
      "Train on 1000 samples, validate on 100 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4956 - acc: 0.8590 - val_loss: 0.5162 - val_acc: 0.8100\n",
      "trained: 205000 / 320000\n",
      "Train on 1000 samples, validate on 100 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4434 - acc: 0.8640 - val_loss: 0.7580 - val_acc: 0.7900\n",
      "trained: 206000 / 320000\n",
      "Train on 1000 samples, validate on 100 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3985 - acc: 0.8850 - val_loss: 0.7706 - val_acc: 0.7900\n",
      "trained: 207000 / 320000\n",
      "Train on 1000 samples, validate on 100 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4355 - acc: 0.8680 - val_loss: 0.8679 - val_acc: 0.7500\n",
      "trained: 208000 / 320000\n",
      "Train on 1000 samples, validate on 100 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.5088 - acc: 0.8360 - val_loss: 0.6506 - val_acc: 0.8200\n",
      "trained: 209000 / 320000\n",
      "Train on 1000 samples, validate on 100 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3924 - acc: 0.8810 - val_loss: 0.6088 - val_acc: 0.8400\n",
      "trained: 210000 / 320000\n",
      "Train on 1000 samples, validate on 100 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4704 - acc: 0.8750 - val_loss: 0.7858 - val_acc: 0.8300\n",
      "trained: 211000 / 320000\n",
      "Train on 1000 samples, validate on 100 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4175 - acc: 0.8740 - val_loss: 0.5682 - val_acc: 0.8200\n",
      "trained: 212000 / 320000\n",
      "Train on 1000 samples, validate on 100 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4765 - acc: 0.8540 - val_loss: 0.6781 - val_acc: 0.8100\n",
      "trained: 213000 / 320000\n",
      "Train on 1000 samples, validate on 100 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4193 - acc: 0.8610 - val_loss: 0.6666 - val_acc: 0.8200\n",
      "trained: 214000 / 320000\n",
      "Train on 1000 samples, validate on 100 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4701 - acc: 0.8690 - val_loss: 0.6533 - val_acc: 0.8200\n",
      "trained: 215000 / 320000\n",
      "Train on 1000 samples, validate on 100 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.5236 - acc: 0.8300 - val_loss: 0.4320 - val_acc: 0.8500\n",
      "trained: 216000 / 320000\n",
      "Train on 1000 samples, validate on 100 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.5030 - acc: 0.8420 - val_loss: 0.7831 - val_acc: 0.7900\n",
      "trained: 217000 / 320000\n",
      "Train on 1000 samples, validate on 100 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4704 - acc: 0.8630 - val_loss: 0.7535 - val_acc: 0.8000\n",
      "trained: 218000 / 320000\n",
      "Train on 1000 samples, validate on 100 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4326 - acc: 0.8760 - val_loss: 0.5514 - val_acc: 0.8200\n",
      "trained: 219000 / 320000\n",
      "Train on 1000 samples, validate on 100 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4824 - acc: 0.8550 - val_loss: 0.5645 - val_acc: 0.8400\n",
      "trained: 220000 / 320000\n",
      "Train on 1000 samples, validate on 100 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4348 - acc: 0.8650 - val_loss: 0.5366 - val_acc: 0.8400\n",
      "trained: 221000 / 320000\n",
      "Train on 1000 samples, validate on 100 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4742 - acc: 0.8580 - val_loss: 0.6529 - val_acc: 0.8300\n",
      "trained: 222000 / 320000\n",
      "Train on 1000 samples, validate on 100 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4545 - acc: 0.8660 - val_loss: 0.8909 - val_acc: 0.7800\n",
      "trained: 223000 / 320000\n",
      "Train on 1000 samples, validate on 100 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4303 - acc: 0.8620 - val_loss: 0.8618 - val_acc: 0.7100\n",
      "trained: 224000 / 320000\n",
      "Train on 1000 samples, validate on 100 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4529 - acc: 0.8660 - val_loss: 0.9747 - val_acc: 0.7700\n",
      "trained: 225000 / 320000\n",
      "Train on 1000 samples, validate on 100 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4016 - acc: 0.8670 - val_loss: 0.4462 - val_acc: 0.8500\n",
      "trained: 226000 / 320000\n",
      "Train on 1000 samples, validate on 100 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4478 - acc: 0.8600 - val_loss: 0.7347 - val_acc: 0.7400\n",
      "trained: 227000 / 320000\n",
      "Train on 1000 samples, validate on 100 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4224 - acc: 0.8690 - val_loss: 0.8192 - val_acc: 0.8000\n",
      "trained: 228000 / 320000\n",
      "Train on 1000 samples, validate on 100 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4348 - acc: 0.8680 - val_loss: 0.5577 - val_acc: 0.8400\n",
      "trained: 229000 / 320000\n",
      "Train on 1000 samples, validate on 100 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4199 - acc: 0.8850 - val_loss: 0.5283 - val_acc: 0.8400\n",
      "trained: 230000 / 320000\n",
      "Train on 1000 samples, validate on 100 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3762 - acc: 0.8940 - val_loss: 0.6727 - val_acc: 0.8200\n",
      "trained: 231000 / 320000\n",
      "Train on 1000 samples, validate on 100 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4733 - acc: 0.8540 - val_loss: 0.5090 - val_acc: 0.8600\n",
      "trained: 232000 / 320000\n",
      "Train on 1000 samples, validate on 100 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4120 - acc: 0.8760 - val_loss: 0.7279 - val_acc: 0.7800\n",
      "trained: 233000 / 320000\n",
      "Train on 1000 samples, validate on 100 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4316 - acc: 0.8630 - val_loss: 0.7299 - val_acc: 0.8000\n",
      "trained: 234000 / 320000\n",
      "Train on 1000 samples, validate on 100 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4243 - acc: 0.8690 - val_loss: 0.8740 - val_acc: 0.7800\n",
      "trained: 235000 / 320000\n",
      "Train on 1000 samples, validate on 100 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4432 - acc: 0.8790 - val_loss: 0.5662 - val_acc: 0.8500\n",
      "trained: 236000 / 320000\n",
      "Train on 1000 samples, validate on 100 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4296 - acc: 0.8710 - val_loss: 0.7068 - val_acc: 0.8000\n",
      "trained: 237000 / 320000\n",
      "Train on 1000 samples, validate on 100 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4355 - acc: 0.8760 - val_loss: 0.7451 - val_acc: 0.7900\n",
      "trained: 238000 / 320000\n",
      "Train on 1000 samples, validate on 100 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4060 - acc: 0.8680 - val_loss: 0.7404 - val_acc: 0.7700\n",
      "trained: 239000 / 320000\n",
      "Train on 1000 samples, validate on 100 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3889 - acc: 0.8810 - val_loss: 0.5167 - val_acc: 0.8100\n",
      "trained: 240000 / 320000\n",
      "Train on 1000 samples, validate on 100 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4415 - acc: 0.8670 - val_loss: 0.7294 - val_acc: 0.7500\n",
      "trained: 241000 / 320000\n",
      "Train on 1000 samples, validate on 100 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4110 - acc: 0.8730 - val_loss: 0.6911 - val_acc: 0.8300\n",
      "trained: 242000 / 320000\n",
      "Train on 1000 samples, validate on 100 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4202 - acc: 0.8660 - val_loss: 0.5891 - val_acc: 0.7800\n",
      "trained: 243000 / 320000\n",
      "Train on 1000 samples, validate on 100 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4627 - acc: 0.8710 - val_loss: 0.7588 - val_acc: 0.8000\n",
      "trained: 244000 / 320000\n",
      "Train on 1000 samples, validate on 100 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3760 - acc: 0.8880 - val_loss: 0.7316 - val_acc: 0.7800\n",
      "trained: 245000 / 320000\n",
      "Train on 1000 samples, validate on 100 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4510 - acc: 0.8620 - val_loss: 0.6929 - val_acc: 0.7900\n",
      "trained: 246000 / 320000\n",
      "Train on 1000 samples, validate on 100 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4852 - acc: 0.8490 - val_loss: 0.6726 - val_acc: 0.8200\n",
      "trained: 247000 / 320000\n",
      "Train on 1000 samples, validate on 100 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.5160 - acc: 0.8460 - val_loss: 0.9835 - val_acc: 0.7200\n",
      "trained: 248000 / 320000\n",
      "Train on 1000 samples, validate on 100 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4833 - acc: 0.8530 - val_loss: 0.7122 - val_acc: 0.7800\n",
      "trained: 249000 / 320000\n",
      "Train on 1000 samples, validate on 100 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3837 - acc: 0.8750 - val_loss: 0.7320 - val_acc: 0.7900\n",
      "trained: 250000 / 320000\n",
      "Train on 1000 samples, validate on 100 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4274 - acc: 0.8770 - val_loss: 0.5490 - val_acc: 0.8100\n",
      "trained: 251000 / 320000\n",
      "Train on 1000 samples, validate on 100 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.4178 - acc: 0.8740 - val_loss: 0.3053 - val_acc: 0.9000\n",
      "trained: 252000 / 320000\n",
      "Train on 1000 samples, validate on 100 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.4397 - acc: 0.8730 - val_loss: 0.6258 - val_acc: 0.8400\n",
      "trained: 253000 / 320000\n",
      "Train on 1000 samples, validate on 100 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.4709 - acc: 0.8570 - val_loss: 0.8569 - val_acc: 0.8300\n",
      "trained: 254000 / 320000\n",
      "Train on 1000 samples, validate on 100 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.4114 - acc: 0.8720 - val_loss: 0.4439 - val_acc: 0.8700\n",
      "trained: 255000 / 320000\n",
      "Train on 1000 samples, validate on 100 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3973 - acc: 0.8900 - val_loss: 0.7506 - val_acc: 0.7400\n",
      "trained: 256000 / 320000\n",
      "Train on 1000 samples, validate on 100 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4170 - acc: 0.8850 - val_loss: 0.7470 - val_acc: 0.7600\n",
      "trained: 257000 / 320000\n",
      "Train on 1000 samples, validate on 100 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.4650 - acc: 0.8610 - val_loss: 0.5353 - val_acc: 0.8200\n",
      "trained: 258000 / 320000\n",
      "Train on 1000 samples, validate on 100 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4202 - acc: 0.8790 - val_loss: 0.7200 - val_acc: 0.8000\n",
      "trained: 259000 / 320000\n",
      "Train on 1000 samples, validate on 100 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3840 - acc: 0.8870 - val_loss: 0.6104 - val_acc: 0.8200\n",
      "trained: 260000 / 320000\n",
      "Train on 1000 samples, validate on 100 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4107 - acc: 0.8710 - val_loss: 0.7201 - val_acc: 0.7900\n",
      "trained: 261000 / 320000\n",
      "Train on 1000 samples, validate on 100 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4219 - acc: 0.8810 - val_loss: 0.8533 - val_acc: 0.7800\n",
      "trained: 262000 / 320000\n",
      "Train on 1000 samples, validate on 100 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4299 - acc: 0.8580 - val_loss: 0.8623 - val_acc: 0.7900\n",
      "trained: 263000 / 320000\n",
      "Train on 1000 samples, validate on 100 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4393 - acc: 0.8640 - val_loss: 0.8803 - val_acc: 0.7600\n",
      "trained: 264000 / 320000\n",
      "Train on 1000 samples, validate on 100 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4740 - acc: 0.8690 - val_loss: 0.6467 - val_acc: 0.8300\n",
      "trained: 265000 / 320000\n",
      "Train on 1000 samples, validate on 100 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3859 - acc: 0.8910 - val_loss: 0.6432 - val_acc: 0.8200\n",
      "trained: 266000 / 320000\n",
      "Train on 1000 samples, validate on 100 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3772 - acc: 0.8840 - val_loss: 0.6570 - val_acc: 0.8100\n",
      "trained: 267000 / 320000\n",
      "Train on 1000 samples, validate on 100 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4035 - acc: 0.8680 - val_loss: 0.6109 - val_acc: 0.7900\n",
      "trained: 268000 / 320000\n",
      "Train on 1000 samples, validate on 100 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4510 - acc: 0.8620 - val_loss: 0.6060 - val_acc: 0.8200\n",
      "trained: 269000 / 320000\n",
      "Train on 1000 samples, validate on 100 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4205 - acc: 0.8800 - val_loss: 0.5532 - val_acc: 0.8000\n",
      "trained: 270000 / 320000\n",
      "Train on 1000 samples, validate on 100 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3976 - acc: 0.8830 - val_loss: 0.8702 - val_acc: 0.7800\n",
      "trained: 271000 / 320000\n",
      "Train on 1000 samples, validate on 100 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4382 - acc: 0.8720 - val_loss: 0.6600 - val_acc: 0.7900\n",
      "trained: 272000 / 320000\n",
      "Train on 1000 samples, validate on 100 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3872 - acc: 0.8860 - val_loss: 0.5688 - val_acc: 0.8700\n",
      "trained: 273000 / 320000\n",
      "Train on 1000 samples, validate on 100 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3400 - acc: 0.8950 - val_loss: 0.8943 - val_acc: 0.7300\n",
      "trained: 274000 / 320000\n",
      "Train on 1000 samples, validate on 100 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4566 - acc: 0.8690 - val_loss: 0.5057 - val_acc: 0.8400\n",
      "trained: 275000 / 320000\n",
      "Train on 1000 samples, validate on 100 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3861 - acc: 0.8890 - val_loss: 0.5738 - val_acc: 0.8400\n",
      "trained: 276000 / 320000\n",
      "Train on 1000 samples, validate on 100 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.4035 - acc: 0.8820 - val_loss: 0.6676 - val_acc: 0.8000\n",
      "trained: 277000 / 320000\n",
      "Train on 1000 samples, validate on 100 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3847 - acc: 0.8840 - val_loss: 0.7103 - val_acc: 0.8100\n",
      "trained: 278000 / 320000\n",
      "Train on 1000 samples, validate on 100 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3567 - acc: 0.8910 - val_loss: 0.4228 - val_acc: 0.8900\n",
      "trained: 279000 / 320000\n",
      "Train on 1000 samples, validate on 100 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4018 - acc: 0.8760 - val_loss: 0.6183 - val_acc: 0.8100\n",
      "trained: 280000 / 320000\n",
      "Train on 1000 samples, validate on 100 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3431 - acc: 0.9010 - val_loss: 0.6032 - val_acc: 0.7700\n",
      "trained: 281000 / 320000\n",
      "Train on 1000 samples, validate on 100 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.5120 - acc: 0.8470 - val_loss: 0.8061 - val_acc: 0.8100\n",
      "trained: 282000 / 320000\n",
      "Train on 1000 samples, validate on 100 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4009 - acc: 0.8650 - val_loss: 0.4559 - val_acc: 0.8600\n",
      "trained: 283000 / 320000\n",
      "Train on 1000 samples, validate on 100 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4199 - acc: 0.8700 - val_loss: 0.7207 - val_acc: 0.7900\n",
      "trained: 284000 / 320000\n",
      "Train on 1000 samples, validate on 100 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4134 - acc: 0.8760 - val_loss: 0.6894 - val_acc: 0.8100\n",
      "trained: 285000 / 320000\n",
      "Train on 1000 samples, validate on 100 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4410 - acc: 0.8600 - val_loss: 0.7162 - val_acc: 0.8100\n",
      "trained: 286000 / 320000\n",
      "Train on 1000 samples, validate on 100 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3712 - acc: 0.8800 - val_loss: 0.6348 - val_acc: 0.8100\n",
      "trained: 287000 / 320000\n",
      "Train on 1000 samples, validate on 100 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4127 - acc: 0.8740 - val_loss: 0.8215 - val_acc: 0.7300\n",
      "trained: 288000 / 320000\n",
      "Train on 1000 samples, validate on 100 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4111 - acc: 0.8760 - val_loss: 0.6991 - val_acc: 0.7700\n",
      "trained: 289000 / 320000\n",
      "Train on 1000 samples, validate on 100 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4521 - acc: 0.8690 - val_loss: 0.6506 - val_acc: 0.8200\n",
      "trained: 290000 / 320000\n",
      "Train on 1000 samples, validate on 100 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3844 - acc: 0.8970 - val_loss: 0.6495 - val_acc: 0.8300\n",
      "trained: 291000 / 320000\n",
      "Train on 1000 samples, validate on 100 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3631 - acc: 0.8980 - val_loss: 0.6254 - val_acc: 0.8300\n",
      "trained: 292000 / 320000\n",
      "Train on 1000 samples, validate on 100 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3687 - acc: 0.8860 - val_loss: 0.6042 - val_acc: 0.8000\n",
      "trained: 293000 / 320000\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#\n",
    "# Define train, validation and test lists\n",
    "#\n",
    "\n",
    "train_labels = []\n",
    "val_labels = []\n",
    "test_labels = []\n",
    "\n",
    "train_input = []\n",
    "val_input = []\n",
    "test_input = []\n",
    "\n",
    "#\n",
    "# Load validation dataset\n",
    "#\n",
    "\n",
    "folder = \"/media/matheusmortatti/External/rvl-cdip\"\n",
    "labels_file = open(folder + \"/labels/val.txt\")\n",
    "\n",
    "val_file = []\n",
    "for line in labels_file:\n",
    "    sp = line.split()\n",
    "    val_file.append(sp)\n",
    "    \n",
    "#\n",
    "# Open training list file and start training\n",
    "#\n",
    "\n",
    "labels_file = open(folder + \"/labels/train.txt\")\n",
    "trained = 0\n",
    "train_size = file_len(folder + \"/labels/train.txt\")\n",
    "\n",
    "for i in range(EPOCHS):\n",
    "    for line in labels_file:\n",
    "        sp = line.split()\n",
    "        pp_img = preprocess_image(imread(folder + \"/images/\" + sp[0]))\n",
    "\n",
    "        train_input.append(pp_img)\n",
    "        train_labels.append(int(sp[1]))\n",
    "\n",
    "        if len(train_input) >= TRAIN_STEP:\n",
    "            \n",
    "            trained += len(train_input)\n",
    "\n",
    "            #\n",
    "            # Choose a subset of the validation data\n",
    "            #\n",
    "\n",
    "            ss_val = choices(val_file, k=VAL_SIZE)\n",
    "\n",
    "            for v in ss_val:\n",
    "                val_input.append(preprocess_image(imread(folder + \"/images/\" + v[0])))\n",
    "                val_labels.append(int(v[1]))\n",
    "\n",
    "            x_val = np.expand_dims(np.asarray(val_input), axis=3)\n",
    "            y_val = make_labels(val_labels)\n",
    "\n",
    "            #\n",
    "            # Create training data\n",
    "            #\n",
    "\n",
    "            x_train = np.expand_dims(np.asarray(train_input), axis=3)\n",
    "            y_train = make_labels(train_labels)\n",
    "\n",
    "            model.fit(x_train, y_train,\n",
    "                      batch_size=BATCH_SIZE,\n",
    "                      epochs=1,\n",
    "                      verbose=1,\n",
    "                      validation_data=(x_val, y_val))\n",
    "\n",
    "            #\n",
    "            # Reset lists for next iteration\n",
    "            #\n",
    "\n",
    "            train_input = []\n",
    "            train_labels = []\n",
    "            val_input = []\n",
    "            val_labels = []\n",
    "            \n",
    "            print(\"trained: \" + str(trained) + \" / \" + str(train_size))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Model and Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_json = model.to_json()\n",
    "with open(\"model.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "model.save_weights(\"model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np_img_type = np.zeros((len(img_type), dt))\n",
    "\n",
    "print(len(img_type))\n",
    "\n",
    "for i in range(len(img_type)):\n",
    "    np_img_type[i, img_type[i]] = 1\n",
    "print(np_img_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.expand_dims(np.asarray(imgs[:2000]), axis=3)\n",
    "y_train = np_img_type[:2000,:]\n",
    "\n",
    "x_val = np.expand_dims(np.asarray(imgs[2000:4000]), axis=3)\n",
    "y_val = np_img_type[2000:4000,:]\n",
    "\n",
    "x_test = np.expand_dims(np.asarray(imgs[4000:]), axis=3)\n",
    "y_test = np_img_type[4000:,:]\n",
    "\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(x_train, y_train,\n",
    "          batch_size=100,\n",
    "          epochs=2,\n",
    "          verbose=1,\n",
    "          validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Confution Matrix and Classification Report\n",
    "Y_pred = model.predict_classes(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = Y_pred\n",
    "y_true = np.argmax(y_test, axis=1)\n",
    "print('Confusion Matrix')\n",
    "print(confusion_matrix(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
